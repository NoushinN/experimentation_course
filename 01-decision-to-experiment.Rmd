---
output:
  word_document: default
  html_document: default
---

# Deciding to experiment

Before embarking on the experimentation journey, you should ask the question ‘Do you have to run an experiment?’ As discussed in Module 1, experiments provide answers to very specific questions – they will likely not answer questions that are not causal in nature. 

Designing an implementing an experiment can take time, motivation, skills, and often financial resources. It is not always immediately clear what combination of resources you will need for your experiment, given that they’re not the first thing considered when trying to answer a question.

Embarking on the experimentation journey will require significant cross-functional collaboration, stakeholder buy-in, and lots of preparatory work – but it all starts with having clear and thoughtful design for your research question, and then landing on an implementation plan before starting.

## What is an experiment?

An experiment is a procedure designed to test a hypothesis as part of the scientific method.

Experimentation is often described as a method, approach, a test, a tool to generate evidence. All of these are true, but first and foremost experimentation is a problem-solving process. The starting point for any experiment should be the problem you are trying to solve.

The two key variables in any experiment are the independent (explanatory) and dependent (response) variables. The independent variable is controlled or changed to test its effects on the dependent variable. Three key types of experiments are controlled experiments, field experiments, and natural experiments.


**Controlled Experiments:** Lab experiments are controlled experiments, although you can perform a controlled experiment outside of a lab setting! In a controlled experiment, you compare an experimental group with a control group. Ideally, these two groups are identical except for one variable, the independent variable.

**Field Experiments:** A field experiment may be either a natural experiment or a controlled experiment. It takes place in a real-world setting, rather than under lab conditions. For example, an experiment involving an animal in its natural habitat would be a field experiment.

**Natural Experiments:** A natural experiment also is called a quasi-experiment. A natural experiment involves making a prediction or forming a hypothesis and then gathering data by observing a system. The variables are not controlled in a natural experiment.

> To summarize: an experiment is simply the test of a hypothesis. A hypothesis, in turn, is a proposed relationship or explanation of phenomena.

## Do we need to experiment? 

To embark on an `experimentation project`, we really need to consider whether _experimentation_ is needed in the first place. One way of determining this is to consider whether there is a very specific question that requires a specific answer? And, is the answer worthy to know? If we are after questions that are not causal in nature, then an experiment is likely not the best fit. 
Making observations or trying something after making a prediction about what you expect will happen, is a type of experiment. For example, predicting/hypothesizing that your coffee will taste sweeter after the addition of sugar and then going ahead to testing that is an experiment.

The following examples, on the other hand, are not experiments:  
- making a model dashboard   
- making a poster  
- changing many factors at once, so one can't truly test the effect of the variables  
- trying something, just to see what happens.   

At this point in the **experimentation cycle**, there are more questions than answers and the more questions one asks, the more clarifying answers one will seek on whether an experiment is really needed. 

_What would experimentation look like in policy or practice? why would an experiment be worth investing in? What data or program performance tracking is already in place? What experimental tools and expertise are available and are they sufficient? What are the risks? What could be a risk management strategy?_

**Decision tree** 

To help make whether an experiment is needed and set one's direction, the following decision tree from Nesta is a great starting point for a project journey. In this journey, only the two red bubbles refer to an experiment. The rest are only explorations or validations. 
What makes the two red bubbles an experiment? What do they have in common? The two red bubbles focus on the trial and error to find out what works and what doesn't, which is central to any experimental project.

<center>
![](fig/decision_tree.jpeg)
</center>


## The experimentation cycle

> A problem well-stated is half-solved!

To help others understand the problem as we see it, one of the first things an experiment needs is well-framed question and clearly articulated goals. To help formulate the `why` as well as the `what`, the following experimentation lifecycle is helpful in that it encourages to reiteratively (1) brainstorm and form vague ideas, (2) group vague ideas, (3) make general observations, (4) hypothesize, (5) determine a model/method to test the hypotheses, (6) do the experiment to test hypothesis, (7) gather data, analyze, and interpret the results, and (8) learn and communicate learnings to stakeholders


<center>
![](fig/experiment_lifecycle.png){width=80%}
</center>

This lifecycle presumes that we can:

- sketch out what information we need to collect (or already have) to get from a vague idea to the hypothesis stage for a planned project
- get invested in the problem before the solution nor in a particular result (any biases will work against us here)
- not get stuck in a fishing expedition (i.e. grouping ideas forever)
- understand the problem well enough to clearly articulate the goals, questions, and hypotheses before building metrics
- select metrics that will help answer the questions. This can include system parameters, workload parameters, behaviours, etc. `“If all you have is a hammer, everything looks like a nail.” - Bernard Baruch`
- identify parameters that affect behaviour or observations and decide which parameters or interactions to study, or vary.

## Design considerations

> Don’t land your plane in forests, and don’t do experimental designs before you have considered its drawbacks

It is important to keep in mind that no experimental design is really perfect in that it can consider all aspects of an issue. This is not to discourage us. In a way, George Box's (British statistician) quote that "All models are wrong, but some are useful" applies to experimental designs as well. 
As long as we remember that one single experimental design cannot be comprehensive and all-encompassing and that it is ok to be specific and clear about limitations. A perfect design doesn't exist because we cannot possibly control for the many factors and behaviours that may affect a situation. 

Therefore, since all models are wrong to some extent, researchers should check the scope of applicability and limitations of their method/model. We should choose the designs that best answer the research question, and not try to tailor the research question to the method at hand. 

For instance, we may decide to base our tests on a set of observations derived from survey findings and not be aware that survey data can fail in several aspects: 
(1) people act differently when they realize they are under study. If asked about questions on sensitive topics (e.g., homosexuality, immigration, abortion, or Donald Trump), people understand there is a “standard” answer and so, they may hide their true feelings and give socially acceptable answers.
(2) having a representative sample is difficult and expensive. In social sciences, one of the basis of experiments is recognizing regional diversity (e.g. British Columbia is different from Ontario and Ontario is different from Quebec). This can affect the interpretation of our findings and their generalizability.
(3) determining the causal relations between two events is usually the goal of experimentation. However, direction of causal inference in social situations can be problematic. Traditional quantitative methods are particularly ill-designed for causal questions when the answer can go in either directions. A solution here is a carefully designed experiment with control groups, more on this later.

Nevertheless, experiments can produce many types of evidence that can be used in program and policy designs. With sufficient sample sizes, for example, randomised control trials can provide useful evidence through pre- and post-experiment analysis. 

For example, a behavioural insights group examined the effect of nudges on health and wellbeing and demonstrated a massive effect _default choices_ have on organ donation compliance rates. Those
countries where people are required to opt-out of organ donation report significantly higher consent than those with an opt-in policy (Johnson & Goldstein (2003), Do Defaults Save Lives?, Science, Vol. 302).  

Another example is another group who examined whether manipulating the positon of food on a restaurant
menu would have any effect on consumer choices. They found that items placed at the beginning or end of the menu were up to twice as popular as when the same items were placed in the centre of the menu (Dayan & Hillel (2011), Nudge to nobesity II: Menu positions influence food orders, Judgment and Decision Making).

# Examine Assumptions and account for Pitfalls
Before designing and running experiments, it helps to examine our assumptions about the topic and clearly track and communicate them. In a similar fashion, statistical models that are later used to analyze collected data also work under assumptions. For example, a simple linear regression model requires four assumptions:

```
- E(y) = Xβ
- Independence
- Equal variance (σ²)
- Normality
```

Without checking these assumptions, we are using the wrong models and generating misguided insights or misinformation. Thus, to reduce reliance on models with un-intended consequences, we need to clearly and transparently examine our assumptions about the topic of interest.

<center>
![](fig/modeling_gonewrong.png){width=80%}
</center>


Another consideration is measuring how much information we need and can get from an experiment (degrees of freedom). Generally, the more variables are included, the less information is left out. 
In contrast, our data analysis models can run out of steam if there are too many variables (problem of big data). Thus, we need to strike a balance between information/data gathering and analysis methods.

To summarize, experiments can be more prone to failure if disregard the following points (not an exhaustive list):

- Devise wrong metrics (i.e. metrics that don't answer the question at hand)
- Have no clear scope (i.e. what are the boundaries for the 'system under test')
- Omit assumptions and limitations of study
- Use unrepresentative metrics, have no comparison groups, or have cross-contamination
- Not recognize the experimental limitations
- Overlook significant parameters that affect the behaviour of a system
- Report average and not variability (fall for tricks of statistics or have no statistics!)
- Have no interpretation of what results mean or overgeneralizing conclusions
- Ignore errors and outliers
- Not consider the ethical issues and scenarios or have informed consent from participants


## It is not all bad

> Evidence-based policy making can be a political ideal 

Experimentation is not all bad news. Many breakthroughs and transformations on many fronts from medicine and technology to social changes for good have come about by a willingness to experiment. For example, experimentation with design of cell phones has resulted in ease of their usability in time.

<center>
![](fig/cellphone_evolution.png){width=80%}
</center>

There are also many advantages to experimentation. For instance, experiments can result in a higher degree of internal validity. Through random assignment of a treatment condition, experimental designs allow us to examine the effect of one variable while keeping other conditions constant. Note that randomization is the key here because it ensures that the treatment and control groups are comparable. Any differences between the two groups can be attributed to the treatment. 

For instance, a group in the U.K. tested differ letter framings on the tax reported behaviour of over 7,300 sole proprietors. The different treatments were offers of assistance with tax forms, rational argument and threats of audit. By and large, the treatments proved effective at encouraging taxpayers to declare more, with the threat messages being the most effective (Hasseldine et al. (2007), Persuasive Communications: Tax Compliance Enforcement Strategies for Sole Proprietors, Contempory Accounting Research).

Experimentation can be good even without prior knowledge. This is because sometimes there may not be a theory or theories may fall short to start with. Since experimentation can directly control how data is generated, the experimental approach can survive and thrive with no previous knowledge. For instance, with no prior knowledge, electoral researchers can carry out a field experiment to examine how different ways of contacting voters would affect the voting turnout.

Experimentation can help clarify mixed results. This is sometimes inherent in observations that are looking at similar phenomena with different measurements or with different data sources. Observational studies often generate mixed results and one way to validate or clarify the existing mixed result is to run an experiment. Again with the example of electoral politics, researchers can chose to run an experiment to detect how campaign spending affects the voters for the incumbent and the challengers differently.

<center>
![](fig/march4science.png){width=80%}
</center>



## Communication of intent to experiment

Given that we are considering the option to experiment, we need to have clear and open communications and collaborations with cross-functional teams. 

The aim is to get feedback from as many diverse people as possible. These conversations can help us decide which ideas to take forward, reiterate clear questions based on feedbacks, and eventually implement in an experimentation proposal. 

These conversations presumes that there is already an executive level buy-in in place and that stakeholders are invested in the experimentation process. This also assumes that a clear and thoughtful design and implementation plan exists before starting to communicate such that it can be communicated wholly and incrementally with the executives. This is not a tautology and hopefully drive the point that iteration, re-iteration, agility, and an open attitude are key qualities in the initial process.

Executive buy-in usually requires a thorough risk assessment and contingency plans more so in the public service space than in academic environments. Therefore, it is important that the executive is aware of the experimentation cycle which can also be thought of as the problem-solving process and endorses the method, approach, tests, and tools that generate evidence. Some, in fact, argue that experimentation is the creation of something new in the face of uncertainty and risk, which requires time, effort and relevant resources.

> It is noteworthy that the word “experimental” has come to mean “innovative” or “radical” rather than simply “untested”. [The Experimenter's Inventory](A catalogue of experiments for decision-makers and professionals)

Genuine experimentation is about committing to rigorous assessments and evaluation  of evidence, not just freewheeling “trying stuff out” or doing things differently and expecting to  succeed.

Therefore, even though a methodology is key to answering a specific question, the starting point is having a problem you are trying to resolve, preferably with the social good in mind. The purpose of experimenting is to test key questions and assumptions using quick, low risk, rigorous experiments. 

From the thousands of experiments conducted by Thomas Edison to create the first lightbulb, or the long-running field experiments by Gregor Mendel to examine genetic variability that today underpins modern agriculture concepts, through to trials in medicine,  carefully testing ideas in practice is a cornerstone of scientific and technological discovery.


## Experiments in the public sphere

Today, experiments are critical to sectors where innovation and optimization are routine, such as web development, digital transformation, electrical vehicles, etc. This has caught on in business such that the largest financial institutions, retailers and restaurants are also running randomized experiments, along with companies like Google, Facebook, and Amazon running tens of thousands of experiments a year. A/B testing is now the standard means through which Silicon Valley improves its online products. However, in government experimentation remains relatively rare and a new field. 

One of the most famous nudge experiments is the ‘Save More Tomorrow’ (SMarT) program that used defaults to increase employees’ savings rates by automatically increasing the percentage of their wage devoted to saving. Average saving rates for SMarT program participants increased from 3.5% to 13.6% over the course of 40 months while savings rates remained stagnant in the other two conditions (Benartzi & Thaler (2004), Save More Tomorrow, Journal of Political Economy).

A small but growing movement of policy experimenters are bringing fresh ideas on how to solve public problems. From crafting better services, to making the back-office of government more efficient, new methods and tools need to be used to develop and test policy. In fact, government must rigorously and systematically put policy to the test – or risk stagnation.

For example, a group conducted three field experiments looking at increasing savings with
text message reminders and found that goal-specific reminders were considerably more effective than
generic ones (Karlan et al. (2010), Getting to the Top of Mind: How Reminders Increase Saving,
NBER Working Paper).

```
In the context of government agencies, experiments aim to evaluate a program, policy, 
or service and test an idea or innovation by investigating what difference it has 
made or will make for the people it is aiming to help. 

```

Like laboratory experiments, public sphere experiments also need a control group to test an innovation against “business-as-usual”. This doesn’t have to be a large trial like testing a drug and can be fast and flexible. In fact, the best experiments start small and as a prototype before they are extended. 

For example, the World Bank advocates for “nimble randomized control trials”. They funded nimble evaluations on how best to improve the take up of health insurance in Azerbaijan, expand the use of contraceptives in Burundi, and support teachers to deliver tailored education to children affected by war and displacement in Lebanon.


##  Summary: deciding to experiment
- Do you need to experiment? Why or why not?
- Find a behaviour, program, policy, or service to test 
- Try out of the box thinking to brainstorm, make observations
- Look for natural experiments
- Talk to experts and get feedback
- Think small and short term
- Start with a proof-of-concept question and hypothesis
- Keep it simple and try to test one thing at a time
- Measure everything that matters
- Have control and treatment groups when possible

